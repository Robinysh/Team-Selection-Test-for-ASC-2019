[paths]
#data directory containing train data in json
train_file_name=data/train.csv
#data directory containing test data in json
test_file_name=data/test.csv
#directory to store processed file for quicker loading 
processed_file=data/formatted_data.npy
#directory to store checkpointed models
save_dir=save/model
#Boolean if load trained model from save
load_model_from_save=False
#continue training from saved model at this path.
#Path must contain files saved by previous training process:
#'config.pkl'  : configuration;
#'checkpoint'  : paths to model file(s) (created by tf).
#                Note: this file contains absolute paths,
#                be careful when moving files around;
#'model.ckpt-*': file(s) with model definition (created by tf)
init_from=save/model

[data]
#minibatch size
batch_size=512
#Percentage of test data from the entire dataset
test_percentage=.2
#Boolean if load data from save
load_data_from_save=True

[log]
#save interval in batches
save_interval=100
#printing interval in batches
print_interval=100
#testing interval in batches and print test loss
test_interval=100
#prediction interval in batches and save predictions
pred_interval=250

[train]
#number of epochs
num_epochs=500
#clip gradients at this value
grad_clip=.5
#learning rate
learning_rate=.002
#decay rate for adam, learning rate decay by decay_rate**epoch_num
decay_rate=0.7
#Dropout probablity for all non-rnn layers
dropout=0.5
#Constant multiplier for regularization loss.
reg_loss=8e-3

[model]
#Size of hidden layers of FC NN
fc_size=[64, 32]

[debug]
#Enables tfdbg. (Debugging takes a lot of memory (~50GB),
#consider this flag deprecated)'
debug=False
#Enables tensorboard logging
tb_logging=False
#log path for tensorboard
log_path=save/model
#RNG seed for tensorflow and numpy
seed=42
