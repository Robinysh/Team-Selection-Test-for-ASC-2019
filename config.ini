[paths]
#data directory containing train data in json
train_file_name=data/train.csv
#data directory containing test data in json
test_file_name=data/test.csv
#directory to store processed file for quicker loading 
processed_file=data/formatted_data.npy
#directory to store checkpointed models
save_dir=save/model
#Boolean if load trained model from save
load_model_from_save=False
#path for infer report
report_path=save/submission.csv

[data]
#minibatch size
batch_size=512
#Percentage of test data from the entire dataset
test_percentage=.2
#Boolean if load data from save
load_data_from_save=False

[log]
#save interval in batches
save_interval=100
#printing interval in batches
print_interval=100
#testing interval in batches and print test loss
test_interval=100
#prediction interval in batches and save predictions
pred_interval=250

[train]
#number of epochs
num_epochs=500
#clip gradients at this value
grad_clip=.5
#learning rate
learning_rate=.001
#decay rate for adam, learning rate decay by decay_rate**epoch_num
decay_rate=0.7
#Dropout probablity for all non-rnn layers
dropout=0.5
#Constant multiplier for regularization loss.
reg_loss=8e-3

[model]
#Size of hidden layers of FC NN
fc_size=[64, 32]
#Dropout probability to be zero
dropout=0.1
#Dropout probability of entire channel
dropout_channel=0.1

[debug]
#Enables tfdbg. (Debugging takes a lot of memory (~50GB),
#consider this flag deprecated)'
debug=False
#Enables tensorboard logging
tb_logging=False
#log path for tensorboard
log_path=save/model
#RNG seed for tensorflow and numpy
seed=42
